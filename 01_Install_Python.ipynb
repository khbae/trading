{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Install_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khbae/trading/blob/master/01_Install_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHVguiwylLTh",
        "colab_type": "text"
      },
      "source": [
        "## This note provides a simple guildeline for installing Python, Tensorflow and Keras.\n",
        "\n",
        "**Python** is an interpreted high-level programming language for general-purpose programming.\n",
        "* https://en.wikipedia.org/wiki/Python_(programming_language)\n",
        "\n",
        "**TensorFlow** is a symbolic math library, and also used for machine learning applications such as neural networks.\n",
        "* https://en.wikipedia.org/wiki/TensorFlow\n",
        "\n",
        "**Keras** is an open source neural network library written in Python. It is capable of running on top of MXNet, Deeplearning4j, **TensorFlow**, Microsoft Cognitive Toolkit or Theano.\n",
        "* https://en.wikipedia.org/wiki/Keras\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYdju0zZnzzT",
        "colab_type": "text"
      },
      "source": [
        "## Install Python\n",
        "\n",
        "Anaconda is a completely free Python distribution (including forcommercial use and redistribution).  It includes more than 300 of the most popular Python packages for science, math, engineering, data analysis. Let's use Anaconda to install Python. \n",
        "\n",
        "### Uninstalling Anaconda\n",
        "\n",
        "If your computer has Anaconda, you can uninstall it by running the following commands from Anaconda Prompt. If not, you can skip this part.\n",
        "\n",
        "<font color=\"blue\">$ conda install anaconda-clean <br>\n",
        "\n",
        "$ anaconda-clean <br>\n",
        "\n",
        "$ anaconda-clean --yes </font>\n",
        "\n",
        "*Note: $ means the command line of Anaconda Prompt.*\n",
        "\n",
        "### Python + Tensorflow + Keras Installation\n",
        "\n",
        "Download Anaconda and Install it with default settings. Install Python 3.6 Version.\n",
        "* https://www.anaconda.com/download/\n",
        "\n",
        "Here are some useful tips on using Anaconda Prompt.\n",
        "* https://conda.io/docs/_downloads/conda-cheatsheet.pdf\n",
        "\n",
        "Create an environment in which to install tensorflow and keras.\n",
        "\n",
        "* https://conda.io/docs/user-guide/tasks/manage-environments.html\n",
        "\n",
        "\n",
        "Run the following commands in Anaconda Prompt.\n",
        "\n",
        "<font color=\"blue\">$ conda update conda<br>\n",
        "\n",
        "$ conda update anaconda<br>\n",
        "\n",
        "$ conda create -n keras python=3.5 anaconda<br>\n",
        "\n",
        "$ activate keras<br>\n",
        "\n",
        "$ conda install -c https://conda.anaconda.org/jjhelmus tensorflow<br>\n",
        "\n",
        "$ conda install -c conda-forge keras<br>\n",
        "\n",
        "$ spyder</font>\n",
        "\n",
        "To confirm the installation of Python, Tensorflow and Keras, let's blindly run the following deep learning example. Now you do not have to understand the code. You will understand it during the semester.\n",
        "\n",
        "* https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8ko0qCalLpY",
        "colab_type": "code",
        "outputId": "c405eabe-9dd4-4f66-fbeb-5b8d6d1a5779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1214
        }
      },
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "!pip install keras\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "20608/60000 [=========>....................] - ETA: 6s - loss: 0.4047 - acc: 0.8755"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.2454 - acc: 0.9250 - val_loss: 0.1028 - val_acc: 0.9680\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1038 - acc: 0.9688 - val_loss: 0.0833 - val_acc: 0.9733\n",
            "Epoch 3/20\n",
            "55552/60000 [==========================>...] - ETA: 0s - loss: 0.0736 - acc: 0.9775"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0728 - acc: 0.9777 - val_loss: 0.0733 - val_acc: 0.9790\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0610 - acc: 0.9819 - val_loss: 0.0761 - val_acc: 0.9783\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0512 - acc: 0.9843 - val_loss: 0.0770 - val_acc: 0.9793\n",
            "Epoch 6/20\n",
            " 1920/60000 [..............................] - ETA: 10s - loss: 0.0375 - acc: 0.9896"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0416 - acc: 0.9877 - val_loss: 0.0879 - val_acc: 0.9795\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0381 - acc: 0.9885 - val_loss: 0.0954 - val_acc: 0.9785\n",
            "Epoch 8/20\n",
            "53632/60000 [=========================>....] - ETA: 1s - loss: 0.0355 - acc: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0359 - acc: 0.9894 - val_loss: 0.0864 - val_acc: 0.9805\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0309 - acc: 0.9910 - val_loss: 0.0885 - val_acc: 0.9815\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0308 - acc: 0.9912 - val_loss: 0.0745 - val_acc: 0.9836\n",
            "Epoch 11/20\n",
            " 1920/60000 [..............................] - ETA: 10s - loss: 0.0127 - acc: 0.9943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0273 - acc: 0.9921 - val_loss: 0.0850 - val_acc: 0.9836\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0271 - acc: 0.9925 - val_loss: 0.0870 - val_acc: 0.9834\n",
            "Epoch 13/20\n",
            "49536/60000 [=======================>......] - ETA: 1s - loss: 0.0240 - acc: 0.9931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0248 - acc: 0.9928 - val_loss: 0.0990 - val_acc: 0.9835\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.0963 - val_acc: 0.9826\n",
            "Epoch 15/20\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0218 - acc: 0.9940 - val_loss: 0.1170 - val_acc: 0.9811\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0204 - acc: 0.9942 - val_loss: 0.1024 - val_acc: 0.9833\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0210 - acc: 0.9942 - val_loss: 0.0977 - val_acc: 0.9856\n",
            "Epoch 18/20\n",
            " 2816/60000 [>.............................] - ETA: 9s - loss: 0.0171 - acc: 0.9954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0206 - acc: 0.9947 - val_loss: 0.1027 - val_acc: 0.9848\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0192 - acc: 0.9951 - val_loss: 0.1097 - val_acc: 0.9832\n",
            "Epoch 20/20\n",
            "52864/60000 [=========================>....] - ETA: 1s - loss: 0.0166 - acc: 0.9956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.1095 - val_acc: 0.9829\n",
            "Test loss: 0.10948700375218873\n",
            "Test accuracy: 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}